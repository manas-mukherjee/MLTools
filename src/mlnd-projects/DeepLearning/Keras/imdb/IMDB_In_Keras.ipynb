{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing IMDB Data in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data\n",
    "This dataset comes preloaded with Keras, so one simple command will get us training and testing data. There is a parameter for how many words we want to look at. We've set it at 1000, but feel free to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data (it's preloaded in Keras)\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=1000)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examining the data\n",
    "Notice that the data has been already pre-processed, where all the words have numbers, and the reviews come in as a vector with the words that the review contains. For example, if the word 'the' is the first one in our dictionary, and a review contains the word 'the', then there is a 1 in the corresponding vector.\n",
    "\n",
    "The output comes as a vector of 1's and 0's, where 1 is a positive sentiment for the review, and 0 is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 61, 362, 2, 645, 149, 4, 2, 7, 14, 123, 199, 4, 402, 672, 23, 4, 2, 5, 4, 303, 663, 23, 2, 223, 5, 36, 119, 12, 13, 286, 2, 4, 123, 69, 60, 2, 501, 4, 86, 42, 333, 811, 146, 2, 17, 8, 51, 2, 32, 7, 4, 177, 2, 207, 110, 98, 2, 17, 545, 2, 5, 246, 6, 320, 634, 2, 2, 23, 4, 2, 28, 2, 164, 21, 2, 795, 23, 89, 4, 402, 672, 71, 38, 76, 128, 74, 4, 303, 672, 2, 13, 92, 67, 6, 226, 176, 7, 2, 4, 2, 5, 2, 2, 2, 4, 172, 469, 21, 36, 81, 2, 49, 87, 84, 367, 4, 96, 61, 577, 47, 276, 4, 2, 23, 41, 657, 2, 38, 382, 4, 2, 7, 318, 944, 5, 2, 80, 2, 49, 641, 23, 32, 7, 14, 13, 82, 657, 2, 224, 49, 532, 2, 486, 44, 4, 2, 40, 23, 430, 892, 182, 121, 36, 2, 4, 117, 799, 18, 35, 436, 811, 42, 38, 5, 54, 6, 275, 284, 303, 287, 56, 395, 41, 36, 942, 41, 121, 442, 77, 5, 59, 560, 2, 42, 54, 402, 201, 2, 2, 2, 287, 56, 18, 4, 312, 396, 2, 36, 942, 90, 121, 240, 77, 5, 29, 560, 120, 50, 2, 8, 4, 173, 7, 4, 2, 115, 617, 34, 4, 370, 159, 660, 2, 443, 2, 858, 56, 5, 620, 125, 268, 443, 2, 112, 160, 109, 37, 317, 449, 73, 279, 50, 80, 30, 35, 963, 283, 363, 65, 23, 14, 42, 142, 13, 16, 43, 2, 8, 67, 2, 2, 123, 56, 18, 4, 2, 59, 16, 210, 31, 7, 61, 2, 45, 99, 78, 12, 426, 28, 77, 6, 53, 2, 177, 2, 4, 2, 2, 43, 161, 605, 12, 18, 72]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One-hot encoding the output\n",
    "Here, we'll turn the input vectors into (0,1)-vectors. For example, if the pre-processed vector contains the number 14, then in the processed vector, the 14th entry will be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1000)\n",
      "(25000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the output into vector mode, each of length 1000\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll also one-hot encode the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the output\n",
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the  model architecture\n",
    "Build a model here using sequential. Feel free to experiment with different layers and sizes! Also, experiment adding dropout to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 501,502\n",
      "Trainable params: 501,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# TODO: Build the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(500, activation='relu', input_shape=(1000,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# TODO: Compile the model using a loss function and an optimizer.\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# TODO : Testing only\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the model\n",
    "Run the model here. Experiment with different batch_size, and number of epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Epoch 1/30\n",
      " - 1s - loss: 0.0075 - acc: 0.9985\n",
      "Epoch 2/30\n",
      " - 1s - loss: 0.0054 - acc: 0.9991\n",
      "Epoch 3/30\n",
      " - 1s - loss: 0.0055 - acc: 0.9988\n",
      "Epoch 4/30\n",
      " - 1s - loss: 0.0052 - acc: 0.9992\n",
      "Epoch 5/30\n",
      " - 1s - loss: 0.0044 - acc: 0.9993\n",
      "Epoch 6/30\n",
      " - 1s - loss: 0.0041 - acc: 0.9993\n",
      "Epoch 7/30\n",
      " - 1s - loss: 0.0036 - acc: 0.9996\n",
      "Epoch 8/30\n",
      " - 1s - loss: 0.0039 - acc: 0.9993\n",
      "Epoch 9/30\n",
      " - 1s - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 10/30\n",
      " - 1s - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 11/30\n",
      " - 1s - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 12/30\n",
      " - 1s - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 13/30\n",
      " - 1s - loss: 0.0026 - acc: 0.9997\n",
      "Epoch 14/30\n",
      " - 1s - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 15/30\n",
      " - 1s - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 16/30\n",
      " - 1s - loss: 0.0025 - acc: 0.9997\n",
      "Epoch 17/30\n",
      " - 1s - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 18/30\n",
      " - 1s - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 19/30\n",
      " - 1s - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 20/30\n",
      " - 1s - loss: 0.0025 - acc: 0.9997\n",
      "Epoch 21/30\n",
      " - 1s - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 22/30\n",
      " - 1s - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 23/30\n",
      " - 1s - loss: 0.0025 - acc: 0.9996\n",
      "Epoch 24/30\n",
      " - 1s - loss: 0.0028 - acc: 0.9996\n",
      "Epoch 25/30\n",
      " - 1s - loss: 0.0027 - acc: 0.9995\n",
      "Epoch 26/30\n",
      " - 1s - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 27/30\n",
      " - 1s - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 28/30\n",
      " - 1s - loss: 0.0021 - acc: 0.9996\n",
      "Epoch 29/30\n",
      " - 1s - loss: 0.0021 - acc: 0.9996\n",
      "Epoch 30/30\n",
      " - 1s - loss: 0.0021 - acc: 0.9997\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "# TODO: Run the model. Feel free to experiment with different batch sizes and number of epochs.\n",
    "print (\"Training started\")\n",
    "model.fit(x_train, y_train, epochs=30, batch_size=512, verbose=2)\n",
    "print (\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCw72RXnCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13486be10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 7s - loss: 0.0234 - acc: 0.9922 - val_loss: 0.7086 - val_acc: 0.8539\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[plot_losses],\n",
    "          verbose=2)\n",
    "# https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating the model\n",
    "This will give you the accuracy of the model, as evaluated on the testing set. Can you get something over 85%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.86007999999999996)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}